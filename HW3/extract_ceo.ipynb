{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled CEO Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Tom Horton', 'Patti Hart', 'Jamie Dimon', 'Steve Cohen', 'Tim Cook']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load labeled dataset\n",
    "ceo_list = []\n",
    "with open('all/ceo.csv','r',encoding='utf-8') as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        name = line.strip().split(\",\")\n",
    "        if name[1] == '':\n",
    "            # means either [\"tim cook\"] or [\"tim\"], simply return name[0]\n",
    "            ceo_list.append(name[0].strip())\n",
    "        else:\n",
    "            # output would be [\"tim\",\"cook\"]\n",
    "            ceo_list.append(name[0] + ' ' + name[1])\n",
    "        line = f.readline()\n",
    "ceo_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All articles extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all files\n",
    "def get_all_files(dir):\n",
    "    files = glob.glob(dir + '/*')\n",
    "    return files\n",
    "files = get_all_files('2013') + get_all_files('2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set stop words,remove them in corpus\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remove Reduntant Words/whitespaces/special chars"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 0 files already\n",
      "reading 100 files already\n",
      "reading 200 files already\n",
      "reading 300 files already\n",
      "reading 400 files already\n",
      "reading 500 files already\n",
      "reading 600 files already\n",
      "reading 700 files already\n",
      "total files: 730\n",
      "total articles: 35898\n"
     ]
    }
   ],
   "source": [
    "# load all articles\n",
    "articles = []\n",
    "for i, file in enumerate(files):\n",
    "    with open(file, 'r', encoding = 'latin-1') as f:\n",
    "        for article in f:\n",
    "            sentences = sent_tokenize(article)\n",
    "            \n",
    "            # remove number, special chars, white spaces and stop words\n",
    "            sentences = [re.sub(r\"[^A-Za-z ]\", \" \", sent) for sent in sentences]\n",
    "            sentences = [sent.strip() for sent in sentences]\n",
    "            sentences = [re.sub(r\" +\",\" \", sent) for sent in sentences]\n",
    "            \n",
    "            sentences = [' '.join([j for j in sent.split() if j.lower() not in stop]) for sent in sentences]\n",
    "            articles.append(sentences)\n",
    "    if i % 100 == 0:\n",
    "        print(f\"reading {i} files already\")\n",
    "print(f'total files: {len(files)}')\n",
    "print(f'total articles: {len(articles)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['UPDATE Fiscal Cliff bill gets closer likely passage Aussie market one markets trading right highs day',\n",
       " 'Hong Kong',\n",
       " 'EARLIER markets open Japan China Holiday futures still closed one open Australia',\n",
       " 'far Washington theatrics problem']"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[3]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Train and Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test dataset\n",
    "train_set = articles[:int(0.6 * len(articles))]\n",
    "test_set = articles[int(0.6 * len(articles)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set size = 21538, test_set size = 14360\n"
     ]
    }
   ],
   "source": [
    "print(f'train_set size = {len(train_set)}, test_set size = {len(test_set)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I'm going to select following features:\n",
    "- first_name_length # the length of first name\n",
    "- last_name_length # the length of last name\n",
    "- contains_ceo # if the sentence contains 'CEO' or not\n",
    "- name_index # the index of the first name char occurs in the sentence\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_in_sent(name, sent):\n",
    "    return ((\" \" + name + \" \" in sent) or (name + \" \" == sent[:len(name)+1]) or (\" \" + name == sent[-len(name)+1:]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "find potential names using **regex**: r'[A-Z][a-z]+ [A-Z][a-z]+'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_df(dataset):\n",
    "    df = []\n",
    "    for i, article in enumerate(dataset):\n",
    "        if i % 1000 == 0: \n",
    "            print(f'Currently prcessing {i} article')\n",
    "        # Get all potential names appeared in this article\n",
    "        names = [re.findall(r'[A-Z][a-z]+ [A-Z][a-z]+', sent) for sent in article]\n",
    "        # flatten the list\n",
    "        names = itertools.chain(*names)\n",
    "        \n",
    "        for name in names:\n",
    "            feature = dict()\n",
    "            for sentence in article:\n",
    "                if not name_in_sent(name, sentence):\n",
    "                    continue\n",
    "                tk = TweetTokenizer()\n",
    "                words = tk.tokenize(sentence)\n",
    "                words_pos = nltk.pos_tag(words)\n",
    "                first_name, last_name = name.split(\" \")\n",
    "                # use pos tag to remove names that are not 'NNP'\n",
    "                pos_first = words_pos[words.index(first_name)][1]\n",
    "                pos_last = words_pos[words.index(last_name)][1]\n",
    "                if (pos_first != 'NNP' or pos_last != 'NNP'):\n",
    "                    continue\n",
    "                feature[\"name\"] = name\n",
    "                \n",
    "                feature[\"first_name_length\"] = len(first_name)\n",
    "                feature[\"last_name_length\"] = len(last_name)\n",
    "                \n",
    "                if 'CEO' in words:\n",
    "                    feature[\"contains_ceo\"] = 1\n",
    "                else:\n",
    "                    feature[\"contains_ceo\"] = 0\n",
    "                feature[\"name_index\"] = words.index(first_name)\n",
    "                feature['is_ceo'] = int(name in ceo_list)\n",
    "                df.append(feature)\n",
    "    return pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently prcessing 0 article\n",
      "Currently prcessing 1000 article\n",
      "Currently prcessing 2000 article\n",
      "Currently prcessing 3000 article\n",
      "Currently prcessing 4000 article\n",
      "Currently prcessing 5000 article\n",
      "Currently prcessing 6000 article\n",
      "Currently prcessing 7000 article\n",
      "Currently prcessing 8000 article\n",
      "Currently prcessing 9000 article\n",
      "Currently prcessing 10000 article\n",
      "Currently prcessing 11000 article\n",
      "Currently prcessing 12000 article\n",
      "Currently prcessing 13000 article\n",
      "Currently prcessing 14000 article\n",
      "Currently prcessing 15000 article\n",
      "Currently prcessing 16000 article\n",
      "Currently prcessing 17000 article\n",
      "Currently prcessing 18000 article\n",
      "Currently prcessing 19000 article\n",
      "Currently prcessing 20000 article\n",
      "Currently prcessing 21000 article\n"
     ]
    }
   ],
   "source": [
    "df_train = generate_feature_df(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    341751\n",
       "1     28953\n",
       "Name: is_ceo, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['is_ceo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data to fit Classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since positive and negative have huge number difference, do a resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = df_train[df_train.is_ceo==1]\n",
    "df_negative = df_train[df_train.is_ceo==0]\n",
    "resample_class = (len(df_positive) + len(df_negative)) // 2\n",
    "df_negative = resample(df_negative, replace = False, n_samples = resample_class)\n",
    "df_positive = resample(df_positive, replace = True, n_samples = resample_class)\n",
    "\n",
    "df_train_over = pd.concat([df_negative, df_positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    185352\n",
       "0    185352\n",
       "Name: is_ceo, dtype: int64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_over['is_ceo'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build test set "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently prcessing 0 article\n",
      "Currently prcessing 1000 article\n",
      "Currently prcessing 2000 article\n",
      "Currently prcessing 3000 article\n",
      "Currently prcessing 4000 article\n",
      "Currently prcessing 5000 article\n",
      "Currently prcessing 6000 article\n",
      "Currently prcessing 7000 article\n",
      "Currently prcessing 8000 article\n",
      "Currently prcessing 9000 article\n",
      "Currently prcessing 10000 article\n",
      "Currently prcessing 11000 article\n",
      "Currently prcessing 12000 article\n",
      "Currently prcessing 13000 article\n",
      "Currently prcessing 14000 article\n"
     ]
    }
   ],
   "source": [
    "df_test = generate_feature_df(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to get performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(truth, predicted):\n",
    "    \n",
    "    \n",
    "    confusion_matrix = metrics.confusion_matrix(truth, predicted)\n",
    "    accuracy = metrics.accuracy_score(truth, predicted)\n",
    "    precision = metrics.precision_score(truth, predicted)\n",
    "    recall = metrics.recall_score(truth, predicted)\n",
    "    F1 = metrics.f1_score(truth, predicted)\n",
    "    \n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix}\\n\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {F1}\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC = RandomForestClassifier(n_estimators=20)\n",
    "use_feature = [i for i in df_train_over.columns if i not in (\"is_ceo\", \"name\")]\n",
    "RFC.fit(df_train_over[use_feature], df_train_over[\"is_ceo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[249443  38148]\n",
      " [  5996   7525]]\n",
      "\n",
      "Accuracy: 0.8533967427402428\n",
      "Precision: 0.16475817222429007\n",
      "Recall: 0.556541675911545\n",
      "F1 Score: 0.25424874142649595\n"
     ]
    }
   ],
   "source": [
    "predict = RFC.predict(df_test[use_feature])\n",
    "get_metrics(df_test.is_ceo, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(df_train_over[use_feature], df_train_over[\"is_ceo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[252067  35524]\n",
      " [  5860   7661]]\n",
      "\n",
      "Accuracy: 0.8625627673423842\n",
      "Precision: 0.17739956003241866\n",
      "Recall: 0.5666001035426373\n",
      "F1 Score: 0.27020068423094556\n"
     ]
    }
   ],
   "source": [
    "predict = xgb.predict(df_test[use_feature])\n",
    "get_metrics(df_test.is_ceo, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='warn',\n",
       "          n_jobs=None, penalty='l2', random_state=None, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "clf = LogisticRegression(solver='lbfgs')\n",
    "clf.fit(df_train_over[use_feature], df_train_over[\"is_ceo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[184797 102794]\n",
      " [  5089   8432]]\n",
      "\n",
      "Accuracy: 0.6417180318286884\n",
      "Precision: 0.07580961286030245\n",
      "Recall: 0.6236225131277272\n",
      "F1 Score: 0.13518561568614879\n"
     ]
    }
   ],
   "source": [
    "predict = clf.predict(df_test[use_feature])\n",
    "get_metrics(df_test.is_ceo, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Naive Bayes Classification Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GaussianNB(priors=None, var_smoothing=1e-09)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gnb = GaussianNB()\n",
    "gnb.fit(df_train_over[use_feature], df_train_over[\"is_ceo\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[204862  82729]\n",
      " [  3959   9562]]\n",
      "\n",
      "Accuracy: 0.7121071229310024\n",
      "Precision: 0.10360706894496755\n",
      "Recall: 0.707196213297833\n",
      "F1 Score: 0.18073564435035724\n"
     ]
    }
   ],
   "source": [
    "predict = gnb.predict(df_test[use_feature])\n",
    "get_metrics(df_test.is_ceo, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Based on before model selection result, we can tell that XGBoost has the top performance"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = xgb.predict(df_train_over[use_feature])\n",
    "ceo_train = list(df_train_over.iloc[np.where(predict_train == 1)].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = xgb.predict(df_test[use_feature])\n",
    "ceo_test = list(df_train_over.iloc[np.where(predict_test == 1)].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"ceo_extracted.csv\",'w') as f:\n",
    "    for ceo in ceo_test + ceo_train:\n",
    "        f.write(ceo + \",\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
