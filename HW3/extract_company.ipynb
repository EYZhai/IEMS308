{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import glob\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "import itertools\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Labeled Company Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Abaxis Inc',\n",
       " 'ACA Financial',\n",
       " 'Alibaba Group Holding Ltd',\n",
       " 'American Bell Telephone Co',\n",
       " 'American Express Co']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# load labeled dataset\n",
    "company_list = []\n",
    "with open('all/companies.csv', 'r', encoding='utf-8') as f:\n",
    "    line = f.readline()\n",
    "    while line:\n",
    "        # stip dots since it will confuse sent_tokenizer \n",
    "        company_list.append(line.strip().strip(\".\"))\n",
    "        line = f.readline()\n",
    "company_list[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### All articles extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load all files\n",
    "def get_all_files(dir):\n",
    "    files = glob.glob(dir + '/*')\n",
    "    return files\n",
    "files = get_all_files('2013') + get_all_files('2014')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set stop words,remove them in corpus\n",
    "stop = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I found there are only two company [20th Centry Fox, 2100 Xeno] which has number in it.\n",
    "Instead of introducing number to drastically complex the computation,\n",
    "I'll hard coded the company name to process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "reading 0 files already\n",
      "reading 100 files already\n",
      "reading 200 files already\n",
      "reading 300 files already\n",
      "reading 400 files already\n",
      "reading 500 files already\n",
      "reading 600 files already\n",
      "reading 700 files already\n",
      "total files: 730\n",
      "total articles: 35898\n"
     ]
    }
   ],
   "source": [
    "# load all articles\n",
    "map_name_to_sent = dict()\n",
    "articles = []\n",
    "special_companies = [\"AT&T\", \"McKinsey & Company\", \"Procter & Gamble\", \"Hilton & Hyland\",\"20th Century Fox\", \"2100 Xeno\"]\n",
    "for i, file in enumerate(files):\n",
    "    with open(file, 'r', encoding = 'latin-1') as f:\n",
    "        for article in f:\n",
    "            sentences = sent_tokenize(article)\n",
    "            # remove number, special chars, white spaces and stop words\n",
    "            for sent in sentences:\n",
    "                for sc in special_companies:\n",
    "                    if sc in sent:\n",
    "                        map_name_to_sent[sc] = ' '.join([j for j in sent.split() if j.lower() not in stop])\n",
    "            sentences = [re.sub(r\"[^A-Za-z-]\", \" \", sent) for sent in sentences]\n",
    "            sentences = [sent.strip() for sent in sentences]\n",
    "            sentences = [re.sub(r\" +\",\" \", sent) for sent in sentences]\n",
    "            \n",
    "            sentences = [' '.join([j for j in sent.split() if j.lower() not in stop]) for sent in sentences]\n",
    "            articles.append(sentences)\n",
    "    if i % 100 == 0:\n",
    "        print(f\"reading {i} files already\")\n",
    "print(f'total files: {len(files)}')\n",
    "print(f'total articles: {len(articles)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'20th Century Fox': 'Courtesy Paramount Pictures 20th Century FoxElon Musk made another appearance \"The Colbert Report\" last night asked host Tesla recently given away patents, Musk replied alarming analogy.',\n",
       " 'McKinsey & Company': 'Reuters/Mike SegarDominic Barton, managing director McKinsey & CompanyMcKinsey prestigious consultancy world.',\n",
       " '2100 Xeno': 'Jay Feuerstein CEO ad Chief Investment Officer 2100 Xenon, investment firm based in√Ç Chicago.',\n",
       " 'AT&T': \"Thomson ReutersThe AT&T logo pictured store Carlsbad, CaliforniaWASHINGTON (Reuters) - Telecommunications giant AT&amp;T Inc agreed pay $105 million settle allegations put unauthorized charges customers' cell phone bills, practice known cramming, Politico reported Wednesday.\",\n",
       " 'Hilton & Hyland': 'Hilton & HylandThe 90-year-old CEO Dole Food Company David Murdock selling gorgeous estate overlooking Los Angeles $30 million, according celebrity real estate blog Real Estalker.'}"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "map_name_to_sent # print special company names that can be took care later"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['Earlier today strong South Korean PMI report',\n",
       "  'latest',\n",
       "  'Taiwan',\n",
       "  'saw rise December PMI',\n",
       "  'report'],\n",
       " ['House prepared vote Senate fiscal cliff bill orchestrated White House Senate Minority Leader Mitch McConnell conservatives railing GOP House Speaker John Boehner caving deal banner leading Drudge Report right Drudge Report'],\n",
       " ['Good news global economy',\n",
       "  'South Korea -- whose heavy reliance global trade -- seen economists canary coalmine came strong PMI report',\n",
       "  'report HSBC South Korea Purchasing Managers IndexTM PMI composite indicator designed provide single-figure snapshot health manufacturing sector registered December',\n",
       "  'improvement November highest reading since May',\n",
       "  'However barely PMI suggested operating conditions little changed since previous month',\n",
       "  'Following six months continuous decline new order volumes increased latest survey period',\n",
       "  'However rate growth slight respondents commenting underlying demand conditions remained fragile economic conditions weak',\n",
       "  'particularly case export markets',\n",
       "  'New export orders fell December seventh successive survey period',\n",
       "  'Markit'],\n",
       " ['UPDATE Fiscal Cliff bill gets closer likely passage Aussie market one markets trading right highs day',\n",
       "  'Hong Kong',\n",
       "  'EARLIER markets open Japan China Holiday futures still closed one open Australia',\n",
       "  'far Washington theatrics problem'],\n",
       " ['Taxes increased almost Americans midnight last night',\n",
       "  'Since half American government Senate approved bill would cut taxes many Americans',\n",
       "  'bill sent half American government House Representatives signed law',\n",
       "  'Republicans House Representatives disgruntled Fiscal Cliff bill Senate approved threatening approve',\n",
       "  'Senate bill calls massive tax cuts Americans including investor owner class dividend taxes much lower Senate bill law took effect last night',\n",
       "  'puts Republicans odd position considering party primary mission cut taxes Taxes already gone',\n",
       "  'Republicans thing standing America gigantic tax cut',\n",
       "  'SEE ALSO Great News Romney Voters -- Congress Socked']]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "articles[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Generate Train and Test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and test dataset\n",
    "train_set = articles[:int(0.6 * len(articles))]\n",
    "test_set = articles[int(0.6 * len(articles)):]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "train_set size = 21538, test_set size = 14360\n"
     ]
    }
   ],
   "source": [
    "print(f'train_set size = {len(train_set)}, test_set size = {len(test_set)}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Feature Selection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "I'm going to select following features:\n",
    "- \"keywords\" \n",
    "\n",
    "    Company has keywords that we can tell from the articles, the keywords are:\n",
    "['Company', 'Inc', 'Corporation', 'Group', 'Co', 'Ltd', 'Management', 'Corp']. If we found those keywords appear in or near the company name, we set the feature to 1, else 0.\n",
    "\n",
    "- \"length_of_name\" indicates the length of company name\n",
    "- \"name_index\" indicates the index of the first occurence of company name."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def name_in_sent(name, sent):\n",
    "    return ((\" \" + name + \" \" in sent) or (name + \" \" == sent[:len(name)+1]) or (\" \" + name == sent[-len(name)+1:]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "keywords = ['Company', 'Inc', 'Corporation', 'Group', 'Co', 'Ltd', 'Management', 'Corp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_feature_df(dataset):\n",
    "    df = []\n",
    "    for i, article in enumerate(dataset):\n",
    "        if i % 1000 == 0: \n",
    "            print(f'Currently prcessing {i} article')\n",
    "        # Get all potential names appeared in this article\n",
    "        names = [re.findall(r\"([A-Z][\\w-]+(\\s+[A-Z][\\w-]*)+)\", sent) for sent in article]\n",
    "        # flatten the list\n",
    "        names = itertools.chain(*names)\n",
    "        \n",
    "        for name in names:\n",
    "            name = name[0]\n",
    "            feature = dict()\n",
    "            for sentence in article:\n",
    "                if not name_in_sent(name, sentence):\n",
    "                    continue\n",
    "                words = sentence.split(\" \")\n",
    "                name_list = name.split(\" \")\n",
    "            \n",
    "                feature[\"name\"] = name\n",
    "                feature[\"length_of_name\"] = len(name)\n",
    "                \n",
    "                for k in keywords:\n",
    "                    if k in words:\n",
    "                        feature['keyword'] = 1\n",
    "                    else:\n",
    "                        feature['keyword'] = 0\n",
    "                \n",
    "                feature[\"name_index\"] = words.index(name_list[0])\n",
    "                feature['is_company'] = int(name in company_list)\n",
    "                df.append(feature)\n",
    "    return pd.DataFrame(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently prcessing 0 article\n",
      "Currently prcessing 1000 article\n",
      "Currently prcessing 2000 article\n",
      "Currently prcessing 3000 article\n",
      "Currently prcessing 4000 article\n",
      "Currently prcessing 5000 article\n",
      "Currently prcessing 6000 article\n",
      "Currently prcessing 7000 article\n",
      "Currently prcessing 8000 article\n",
      "Currently prcessing 9000 article\n",
      "Currently prcessing 10000 article\n",
      "Currently prcessing 11000 article\n",
      "Currently prcessing 12000 article\n",
      "Currently prcessing 13000 article\n",
      "Currently prcessing 14000 article\n",
      "Currently prcessing 15000 article\n",
      "Currently prcessing 16000 article\n",
      "Currently prcessing 17000 article\n",
      "Currently prcessing 18000 article\n",
      "Currently prcessing 19000 article\n",
      "Currently prcessing 20000 article\n",
      "Currently prcessing 21000 article\n"
     ]
    }
   ],
   "source": [
    "df_train = generate_feature_df(train_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    273668\n",
       "1     22271\n",
       "Name: is_company, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train['is_company'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using data to fit Classification model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since positive and negative have huge number difference, do resampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn\n",
    "from sklearn import metrics\n",
    "from sklearn.utils import resample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_positive = df_train[df_train.is_company==1]\n",
    "df_negative = df_train[df_train.is_company==0]\n",
    "resample_class = (len(df_positive) + len(df_negative)) // 2\n",
    "df_negative = resample(df_negative, replace = False, n_samples = resample_class)\n",
    "df_positive = resample(df_positive, replace = True, n_samples = resample_class)\n",
    "\n",
    "df_train_over = pd.concat([df_negative, df_positive])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    147969\n",
       "0    147969\n",
       "Name: is_company, dtype: int64"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_train_over[\"is_company\"].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Buid test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Currently prcessing 0 article\n",
      "Currently prcessing 1000 article\n",
      "Currently prcessing 2000 article\n",
      "Currently prcessing 3000 article\n",
      "Currently prcessing 4000 article\n",
      "Currently prcessing 5000 article\n",
      "Currently prcessing 6000 article\n",
      "Currently prcessing 7000 article\n",
      "Currently prcessing 8000 article\n",
      "Currently prcessing 9000 article\n",
      "Currently prcessing 10000 article\n",
      "Currently prcessing 11000 article\n",
      "Currently prcessing 12000 article\n",
      "Currently prcessing 13000 article\n",
      "Currently prcessing 14000 article\n"
     ]
    }
   ],
   "source": [
    "df_test = generate_feature_df(test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to get performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_metrics(truth, predicted):\n",
    "    \n",
    "    \n",
    "    confusion_matrix = metrics.confusion_matrix(truth, predicted)\n",
    "    accuracy = metrics.accuracy_score(truth, predicted)\n",
    "    precision = metrics.precision_score(truth, predicted)\n",
    "    recall = metrics.recall_score(truth, predicted)\n",
    "    F1 = metrics.f1_score(truth, predicted)\n",
    "    \n",
    "    print(f\"Confusion Matrix:\\n {confusion_matrix}\\n\")\n",
    "    print(f\"Accuracy: {accuracy}\")\n",
    "    print(f\"Precision: {precision}\")\n",
    "    print(f\"Recall: {recall}\")\n",
    "    print(f\"F1 Score: {F1}\")\n",
    "    \n",
    "    return"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "            max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "            min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "            min_samples_leaf=1, min_samples_split=2,\n",
       "            min_weight_fraction_leaf=0.0, n_estimators=20, n_jobs=None,\n",
       "            oob_score=False, random_state=None, verbose=0,\n",
       "            warm_start=False)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFC = RandomForestClassifier(n_estimators=20)\n",
    "use_feature = [i for i in df_train_over.columns if i not in (\"is_company\", \"name\")]\n",
    "RFC.fit(df_train_over[use_feature], df_train_over[\"is_company\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[146799  60755]\n",
      " [ 12038  12928]]\n",
      "\n",
      "Accuracy: 0.6869387579563049\n",
      "Precision: 0.17545431103510986\n",
      "Recall: 0.5178242409677161\n",
      "F1 Score: 0.26210098429786416\n"
     ]
    }
   ],
   "source": [
    "predict = RFC.predict(df_test[use_feature])\n",
    "get_metrics(df_test.is_company, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### XGBoost Classification model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, learning_rate=0.1, max_delta_step=0,\n",
       "       max_depth=3, min_child_weight=1, missing=None, n_estimators=100,\n",
       "       n_jobs=1, nthread=None, objective='binary:logistic', random_state=0,\n",
       "       reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
       "       silent=True, subsample=1)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb = XGBClassifier()\n",
    "xgb.fit(df_train_over[use_feature], df_train_over[\"is_company\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Confusion Matrix:\n",
      " [[147015  60539]\n",
      " [ 12747  12219]]\n",
      "\n",
      "Accuracy: 0.6848185102356786\n",
      "Precision: 0.16794029522526732\n",
      "Recall: 0.4894256188416246\n",
      "F1 Score: 0.2500716303057591\n"
     ]
    }
   ],
   "source": [
    "predict = xgb.predict(df_test[use_feature])\n",
    "get_metrics(df_test.is_company, predict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Output result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_train = RFC.predict(df_train_over[use_feature])\n",
    "comp_train = list(df_train_over.iloc[np.where(predict_train == 1)].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "predict_test = RFC.predict(df_test[use_feature])\n",
    "comp_test = list(df_train_over.iloc[np.where(predict_test == 1)].name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"company_extracted.csv\",'w') as f:\n",
    "    for company in comp_test + comp_train:\n",
    "        f.write(company + \",\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
